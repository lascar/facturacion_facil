<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Testing Avanzado - Tutorial CodificaciÃ³n Avanzada</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ğŸ§ª</text></svg>">
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ§ª Testing Avanzado</h1>
            <p>Suite Completa de Tests con Pytest, Coverage y Mocking</p>
        </div>

        <div class="nav">
            <a href="index.html">ğŸ  Inicio</a>
            <a href="01-arquitectura-codigo.html">ğŸ—ï¸ Arquitectura</a>
            <a href="02-configuracion-sistema.html">âš™ï¸ ConfiguraciÃ³n</a>
            <a href="03-base-datos-avanzada.html">ğŸ—„ï¸ Base de Datos</a>
            <a href="04-customtkinter-avanzado.html">ğŸ¨ CustomTkinter</a>
            <a href="05-sistema-ventanas.html">ğŸªŸ Sistema Ventanas</a>
            <a href="06-logging-debugging.html">ğŸ› Logging & Debug</a>
            <a href="07-testing-avanzado.html" class="active">ğŸ§ª Testing</a>
            <a href="08-patrones-diseno.html">ğŸ”§ Patrones</a>
            <a href="09-optimizacion-performance.html">âš¡ Performance</a>
        </div>

        <div class="alert alert-info">
            <h4>ğŸ¯ FilosofÃ­a de Testing Profesional</h4>
            <p>FacturaciÃ³n FÃ¡cil implementa una <strong>suite de testing de nivel empresarial</strong> con 243+ tests organizados por categorÃ­as, markers pytest personalizados, coverage del 22%+ y herramientas avanzadas de mocking. El sistema estÃ¡ diseÃ±ado para garantizar la calidad y prevenir regresiones.</p>
        </div>

        <div class="card">
            <div class="card-header">
                ğŸ—ï¸ Arquitectura del Sistema de Testing
            </div>
            <div class="card-body">
                <div class="row">
                    <div class="col">
                        <h3>ğŸ“Š Estructura de Tests</h3>
                        <pre><code>test/
â”œâ”€â”€ unit/                    # Tests unitarios (rÃ¡pidos)
â”‚   â”œâ”€â”€ test_models.py      # Tests de modelos de datos
â”‚   â”œâ”€â”€ test_validators.py  # Tests de validaciÃ³n
â”‚   â”œâ”€â”€ test_logging_system.py # Tests de logging
â”‚   â”œâ”€â”€ test_security.py    # Tests de seguridad
â”‚   â””â”€â”€ test_pytest_markers.py # Tests de configuraciÃ³n
â”œâ”€â”€ integration/            # Tests de integraciÃ³n
â”‚   â”œâ”€â”€ test_facturas_integration.py
â”‚   â”œâ”€â”€ test_stock_facturacion_integration.py
â”‚   â””â”€â”€ test_complete_functionality.py
â”œâ”€â”€ ui/                     # Tests de interfaz
â”‚   â”œâ”€â”€ test_productos_interface.py
â”‚   â”œâ”€â”€ test_stock_interface.py
â”‚   â””â”€â”€ test_window_management.py
â”œâ”€â”€ performance/            # Tests de rendimiento
â”‚   â”œâ”€â”€ test_database_performance.py
â”‚   â””â”€â”€ test_query_optimization.py
â”œâ”€â”€ regression/             # Tests de regresiÃ³n
â”‚   â””â”€â”€ test_bug_fixes.py
â”œâ”€â”€ conftest.py            # ConfiguraciÃ³n pytest
â”œâ”€â”€ pytest.ini            # ConfiguraciÃ³n markers
â””â”€â”€ .coveragerc           # ConfiguraciÃ³n coverage</code></pre>
                    </div>
                    <div class="col">
                        <h3>ğŸ·ï¸ Markers Pytest Personalizados</h3>
                        <table>
                            <thead>
                                <tr>
                                    <th>Marker</th>
                                    <th>DescripciÃ³n</th>
                                    <th>Uso</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><strong>@pytest.mark.unit</strong></td>
                                    <td>Tests unitarios rÃ¡pidos</td>
                                    <td>pytest -m unit</td>
                                </tr>
                                <tr>
                                    <td><strong>@pytest.mark.integration</strong></td>
                                    <td>Tests de integraciÃ³n</td>
                                    <td>pytest -m integration</td>
                                </tr>
                                <tr>
                                    <td><strong>@pytest.mark.ui</strong></td>
                                    <td>Tests de interfaz</td>
                                    <td>pytest -m ui</td>
                                </tr>
                                <tr>
                                    <td><strong>@pytest.mark.slow</strong></td>
                                    <td>Tests lentos</td>
                                    <td>pytest -m slow</td>
                                </tr>
                                <tr>
                                    <td><strong>@pytest.mark.performance</strong></td>
                                    <td>Tests de rendimiento</td>
                                    <td>pytest -m performance</td>
                                </tr>
                                <tr>
                                    <td><strong>@pytest.mark.regression</strong></td>
                                    <td>Tests de regresiÃ³n</td>
                                    <td>pytest -m regression</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-header">
                âš™ï¸ ConfiguraciÃ³n Pytest Avanzada
            </div>
            <div class="card-body">
                <h3>ğŸ”§ pytest.ini - ConfiguraciÃ³n Principal</h3>
                <p>El archivo <code>pytest.ini</code> configura el comportamiento completo del sistema de testing:</p>
                
                <pre><code># test/pytest.ini - ConfiguraciÃ³n Completa de Pytest
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts =
    --cov=.                    # Coverage de todo el proyecto
    --cov-report=html          # Reporte HTML de coverage
    --cov-report=term-missing  # Reporte en terminal con lÃ­neas faltantes
    --cov-config=.coveragerc   # Archivo de configuraciÃ³n de coverage
    -v                         # Verbose output
    --tb=short                 # Traceback corto
    --import-mode=importlib    # Modo de importaciÃ³n moderno
filterwarnings =
    ignore::ResourceWarning
    ignore::DeprecationWarning
    ignore::pytest.PytestCollectionWarning
    ignore:.*CTkLabel Warning.*:UserWarning
markers =
    unit: Unit tests
    integration: Integration tests
    ui: UI tests
    slow: Slow running tests that may take longer to execute
    performance: Performance and benchmark tests
    regression: Regression tests to prevent bugs from reappearing</code></pre>

                <h3>ğŸ“Š .coveragerc - ConfiguraciÃ³n de Coverage</h3>
                <pre><code># .coveragerc - ConfiguraciÃ³n de Coverage
[run]
source = .
omit = 
    tests/*
    test_*.py
    */__pycache__/*
    */venv/*
    */env/*
    setup.py
    conftest.py

[report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod

[html]
directory = htmlcov</code></pre>

                <div class="row">
                    <div class="col">
                        <h3>ğŸ¯ CaracterÃ­sticas de ConfiguraciÃ³n</h3>
                        <ul>
                            <li><strong>Coverage AutomÃ¡tico:</strong> Se ejecuta en cada test run</li>
                            <li><strong>Reportes MÃºltiples:</strong> HTML + Terminal con lÃ­neas faltantes</li>
                            <li><strong>Filtros de Warnings:</strong> Suprime warnings irrelevantes</li>
                            <li><strong>Markers Personalizados:</strong> CategorizaciÃ³n avanzada</li>
                            <li><strong>Exclusiones Inteligentes:</strong> Omite archivos de test y cache</li>
                        </ul>
                    </div>
                    <div class="col">
                        <h3>ğŸ“‹ Comandos de Testing</h3>
                        <pre><code># Tests rÃ¡pidos (sin slow)
pytest -m 'not slow'

# Solo tests unitarios
pytest -m unit

# Tests con coverage detallado
pytest --cov=database --cov=utils --cov-report=html

# Tests especÃ­ficos
pytest test/unit/test_models.py -v

# Tests en paralelo
pytest -n auto</code></pre>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-header">
                ğŸ§ª conftest.py - Fixtures Avanzadas
            </div>
            <div class="card-body">
                <h3>ğŸ—ï¸ Sistema de Fixtures Reutilizables</h3>
                <p>El archivo <code>conftest.py</code> proporciona fixtures avanzadas para testing aislado:</p>
                
                <pre><code># test/conftest.py - Fixtures Avanzadas
import pytest
import os
import sys
import tempfile
import sqlite3
from faker import Faker

# Configurar Faker en espaÃ±ol
fake = Faker('es_ES')

@pytest.fixture(scope="session")
def faker_instance():
    """Instancia de Faker configurada en espaÃ±ol"""
    return fake

@pytest.fixture(scope="function")
def temp_db():
    """Base de datos temporal para cada test"""
    # Crear archivo temporal
    fd, temp_path = tempfile.mkstemp(suffix='.db')
    os.close(fd)
    
    try:
        # Crear instancia de base de datos temporal
        from database.database import Database
        temp_database = Database(temp_path)
        temp_database.init_database()
        
        yield temp_database
        
    finally:
        # Limpiar archivo temporal
        try:
            os.unlink(temp_path)
        except OSError:
            pass

@pytest.fixture(autouse=True)
def setup_test_environment(monkeypatch, temp_db, request):
    """Configurar entorno de test automÃ¡ticamente"""
    # Obtener el nombre del test
    test_name = request.node.name if hasattr(request, 'node') else 'unknown'

    # Usar base de datos temporal
    monkeypatch.setattr('database.database.db', temp_db)
    monkeypatch.setattr('database.models.db', temp_db)

    # Crear directorio temporal para assets
    test_assets_dir = test_db_manager.create_test_directory(f"{test_name}_assets")
    monkeypatch.setattr('os.makedirs', lambda path, exist_ok=True: None)

    yield

    # El cleanup es automÃ¡tico

@pytest.fixture
def isolated_db(request):
    """Base de datos completamente aislada para tests especiales"""
    test_name = request.node.name if hasattr(request, 'node') else 'isolated'

    with isolated_test_db(test_name) as db:
        yield db

@pytest.fixture
def clean_db(temp_db):
    """Base de datos limpia antes de cada test"""
    # Resetear la base de datos
    test_db_manager.reset_database(temp_db)
    yield temp_db

@pytest.fixture
def mock_messagebox(mocker):
    """Mock para tkinter.messagebox"""
    return mocker.patch('tkinter.messagebox')

@pytest.fixture
def mock_filedialog(mocker):
    """Mock para tkinter.filedialog"""
    return mocker.patch('tkinter.filedialog')

# Hooks pytest para cleanup automÃ¡tico
def pytest_runtest_teardown(item, nextitem):
    """Cleanup despuÃ©s de cada test"""
    test_db_manager.cleanup_test_resources()

def pytest_sessionfinish(session, exitstatus):
    """Cleanup al final de todos los tests"""
    test_db_manager.cleanup_all_test_resources()
    
    # Mostrar estadÃ­sticas finales
    stats = test_db_manager.get_test_stats()
    if stats['total_databases'] > 0:
        print(f"\nğŸ§¹ Cleanup final: {stats['total_databases']} DBs limpiadas")

def pytest_configure(config):
    """ConfiguraciÃ³n pytest"""
    # Variables de entorno para tests
    os.environ['PYTEST_RUNNING'] = '1'
    os.environ['DISABLE_PDF_OPEN'] = '1'
    
    # AÃ±adir markers personalizados
    config.addinivalue_line(
        "markers", "isolated_db: tests que requieren DB completamente aislada"
    )</code></pre>

                <div class="alert alert-success">
                    <h4>ğŸ¯ Beneficios de las Fixtures Avanzadas</h4>
                    <ul>
                        <li><strong>Aislamiento Completo:</strong> Cada test tiene su propia DB temporal</li>
                        <li><strong>Cleanup AutomÃ¡tico:</strong> Recursos limpiados automÃ¡ticamente</li>
                        <li><strong>Mocking Integrado:</strong> Mocks para UI components</li>
                        <li><strong>Faker Integration:</strong> Datos de prueba realistas en espaÃ±ol</li>
                        <li><strong>Environment Control:</strong> Variables de entorno para tests</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-header">
                ğŸ”¬ Tests Unitarios Avanzados
            </div>
            <div class="card-body">
                <h3>ğŸ§ª Ejemplo de Test Unitario Completo</h3>
                <p>Los tests unitarios implementan mocking avanzado y validaciÃ³n exhaustiva:</p>
                
                <pre><code># test/unit/test_models.py - Tests Unitarios Avanzados
import pytest
from unittest.mock import Mock, patch
from database.models import Producto, Factura, Stock

class TestProductoModel:
    """Suite de tests para el modelo Producto"""
    
    @pytest.mark.unit
    def test_producto_creation(self, temp_db):
        """Test creaciÃ³n bÃ¡sica de producto"""
        producto = Producto(
            nombre="Test Product",
            referencia="TEST-001",
            precio=10.50,
            categoria="Test Category",
            descripcion="Test Description",
            iva_recomendado=21.0
        )
        
        # Verificar atributos
        assert producto.nombre == "Test Product"
        assert producto.referencia == "TEST-001"
        assert producto.precio == 10.50
        assert producto.iva_recomendado == 21.0
    
    @pytest.mark.unit
    def test_producto_save_new(self, temp_db):
        """Test guardado de producto nuevo"""
        producto = Producto(
            nombre="New Product",
            referencia="NEW-001",
            precio=15.75
        )
        
        # Guardar producto
        producto_id = producto.save()
        
        # Verificar que se asignÃ³ ID
        assert producto_id is not None
        assert producto.id == producto_id
        
        # Verificar que se puede recuperar
        retrieved = Producto.get_by_id(producto_id)
        assert retrieved is not None
        assert retrieved.nombre == "New Product"
        assert retrieved.referencia == "NEW-001"
    
    @pytest.mark.unit
    def test_producto_save_update(self, temp_db):
        """Test actualizaciÃ³n de producto existente"""
        # Crear y guardar producto
        producto = Producto(nombre="Original", referencia="ORIG-001", precio=10.0)
        original_id = producto.save()
        
        # Modificar producto
        producto.nombre = "Modified"
        producto.precio = 20.0
        updated_id = producto.save()
        
        # Verificar que es actualizaciÃ³n, no creaciÃ³n
        assert updated_id == original_id
        
        # Verificar cambios
        retrieved = Producto.get_by_id(original_id)
        assert retrieved.nombre == "Modified"
        assert retrieved.precio == 20.0
    
    @pytest.mark.unit
    def test_producto_validation(self, temp_db):
        """Test validaciÃ³n de datos de producto"""
        # Test con datos invÃ¡lidos
        with pytest.raises(ValueError):
            producto = Producto(nombre="", referencia="", precio=-1.0)
            producto.validate()
        
        # Test con datos vÃ¡lidos
        producto = Producto(
            nombre="Valid Product",
            referencia="VALID-001",
            precio=10.0
        )
        assert producto.validate() == True
    
    @pytest.mark.unit
    @patch('database.database.db.execute_query')
    def test_producto_get_all_with_mock(self, mock_execute):
        """Test get_all con mock de base de datos"""
        # Configurar mock
        mock_execute.return_value = [
            {
                'id': 1, 'nombre': 'Product 1', 'referencia': 'P001',
                'precio': 10.0, 'categoria': 'Cat1', 'descripcion': 'Desc1',
                'imagen_path': '', 'iva_recomendado': 21.0
            },
            {
                'id': 2, 'nombre': 'Product 2', 'referencia': 'P002',
                'precio': 20.0, 'categoria': 'Cat2', 'descripcion': 'Desc2',
                'imagen_path': '', 'iva_recomendado': 21.0
            }
        ]
        
        # Ejecutar mÃ©todo
        productos = Producto.get_all()
        
        # Verificar resultados
        assert len(productos) == 2
        assert productos[0].nombre == 'Product 1'
        assert productos[1].nombre == 'Product 2'
        
        # Verificar que se llamÃ³ al mock
        mock_execute.assert_called_once_with("SELECT * FROM productos ORDER BY nombre")</code></pre>

                <div class="row">
                    <div class="col">
                        <h3>ğŸ¯ TÃ©cnicas de Testing Unitario</h3>
                        <ul>
                            <li><strong>Isolation:</strong> Cada test es independiente</li>
                            <li><strong>Mocking:</strong> Mock de dependencias externas</li>
                            <li><strong>Assertions:</strong> Verificaciones exhaustivas</li>
                            <li><strong>Edge Cases:</strong> Test de casos lÃ­mite</li>
                            <li><strong>Error Handling:</strong> Test de manejo de errores</li>
                        </ul>
                    </div>
                    <div class="col">
                        <h3>ğŸ“Š Cobertura de Tests</h3>
                        <ul>
                            <li><strong>Models:</strong> 85%+ coverage</li>
                            <li><strong>Utils:</strong> 75%+ coverage</li>
                            <li><strong>Database:</strong> 70%+ coverage</li>
                            <li><strong>UI Components:</strong> 45%+ coverage</li>
                            <li><strong>Total:</strong> 22%+ y creciendo</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-header">
                ğŸ”— Tests de IntegraciÃ³n
            </div>
            <div class="card-body">
                <h3>ğŸŒ Testing de Workflows Completos</h3>
                <p>Los tests de integraciÃ³n verifican el funcionamiento conjunto de mÃºltiples componentes:</p>
                
                <pre><code># test/integration/test_facturas_integration.py - Tests de IntegraciÃ³n
import pytest
from database.models import Producto, Factura, FacturaItem, Stock

class TestFacturasIntegration:
    """Tests de integraciÃ³n para el workflow completo de facturas"""
    
    @pytest.mark.integration
    def test_complete_factura_workflow(self, temp_db):
        """Test del workflow completo de creaciÃ³n de factura"""
        
        # 1. Crear productos
        producto1 = Producto(
            nombre="Laptop Dell",
            referencia="DELL-001",
            precio=800.0,
            iva_recomendado=21.0
        )
        producto1.save()
        
        producto2 = Producto(
            nombre="Mouse Logitech",
            referencia="LOG-001",
            precio=25.0,
            iva_recomendado=21.0
        )
        producto2.save()
        
        # 2. Crear stock inicial
        stock1 = Stock(producto_id=producto1.id, cantidad_disponible=10)
        stock1.save()
        
        stock2 = Stock(producto_id=producto2.id, cantidad_disponible=50)
        stock2.save()
        
        # 3. Crear factura
        factura = Factura(
            numero_factura="FACT-001",
            fecha_factura="2024-12-01",
            nombre_cliente="Cliente Test",
            subtotal=0.0,
            total_iva=0.0,
            total_factura=0.0,
            modo_pago="efectivo"
        )
        factura.save()
        
        # 4. AÃ±adir items a la factura
        item1 = FacturaItem(
            factura_id=factura.id,
            producto_id=producto1.id,
            cantidad=2,
            precio_unitario=800.0,
            iva_porcentaje=21.0
        )
        item1.calculate_totals()
        item1.save()
        
        item2 = FacturaItem(
            factura_id=factura.id,
            producto_id=producto2.id,
            cantidad=3,
            precio_unitario=25.0,
            iva_porcentaje=21.0
        )
        item2.calculate_totals()
        item2.save()
        
        # 5. Actualizar totales de factura
        factura.calculate_totals()
        factura.save()
        
        # 6. Actualizar stock
        stock1.cantidad_disponible -= 2
        stock1.save()
        
        stock2.cantidad_disponible -= 3
        stock2.save()
        
        # 7. Verificaciones del workflow completo
        
        # Verificar factura
        factura_saved = Factura.get_by_id(factura.id)
        assert factura_saved.numero_factura == "FACT-001"
        assert factura_saved.subtotal == 1675.0  # (800*2) + (25*3)
        assert factura_saved.total_iva == 351.75  # 21% de 1675
        assert factura_saved.total_factura == 2026.75  # 1675 + 351.75
        
        # Verificar items
        items = FacturaItem.get_by_factura_id(factura.id)
        assert len(items) == 2
        
        # Verificar stock actualizado
        stock1_updated = Stock.get_by_producto_id(producto1.id)
        assert stock1_updated.cantidad_disponible == 8  # 10 - 2
        
        stock2_updated = Stock.get_by_producto_id(producto2.id)
        assert stock2_updated.cantidad_disponible == 47  # 50 - 3
    
    @pytest.mark.integration
    @pytest.mark.slow
    def test_bulk_factura_creation(self, temp_db, faker_instance):
        """Test de creaciÃ³n masiva de facturas (test lento)"""
        
        # Crear productos base
        productos = []
        for i in range(10):
            producto = Producto(
                nombre=faker_instance.word(),
                referencia=f"BULK-{i:03d}",
                precio=faker_instance.pyfloat(left_digits=2, right_digits=2, positive=True),
                iva_recomendado=21.0
            )
            producto.save()
            productos.append(producto)
        
        # Crear 100 facturas
        facturas_created = []
        for i in range(100):
            factura = Factura(
                numero_factura=f"BULK-{i:04d}",
                fecha_factura=faker_instance.date(),
                nombre_cliente=faker_instance.name(),
                subtotal=0.0,
                total_iva=0.0,
                total_factura=0.0,
                modo_pago=faker_instance.random_element(["efectivo", "tarjeta", "transferencia"])
            )
            factura.save()
            facturas_created.append(factura)
        
        # Verificar que todas se crearon
        all_facturas = Factura.get_all()
        assert len(all_facturas) >= 100
        
        # Verificar integridad de datos
        for factura in facturas_created[:10]:  # Verificar las primeras 10
            retrieved = Factura.get_by_id(factura.id)
            assert retrieved is not None
            assert retrieved.numero_factura == factura.numero_factura</code></pre>

                <div class="alert alert-warning">
                    <h4>ğŸ¯ CaracterÃ­sticas de Tests de IntegraciÃ³n</h4>
                    <ul>
                        <li><strong>Workflows Completos:</strong> Test de procesos end-to-end</li>
                        <li><strong>MÃºltiples Componentes:</strong> InteracciÃ³n entre modelos</li>
                        <li><strong>Datos Realistas:</strong> Uso de Faker para datos de prueba</li>
                        <li><strong>Performance Testing:</strong> Tests de carga con marker @slow</li>
                        <li><strong>Data Integrity:</strong> VerificaciÃ³n de integridad referencial</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="navigation-buttons">
            <a href="06-logging-debugging.html" class="btn btn-secondary">â¬…ï¸ Logging & Debugging</a>
            <a href="08-patrones-diseno.html" class="btn btn-primary">Siguiente: Patrones de DiseÃ±o â¡ï¸</a>
        </div>

        <div class="footer">
            <p>&copy; 2024 FacturaciÃ³n FÃ¡cil - Tutorial de CodificaciÃ³n Avanzada</p>
        </div>
    </div>

    <script src="enhance_code_blocks.js"></script>
</body>
</html>
